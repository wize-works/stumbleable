# Batch Upload Schema Fix - Complete

**Date**: October 4, 2025  
**Issue**: Database schema mismatch causing insert failures  
**Status**: âœ… **FIXED**

---

## ğŸ” Problem Analysis

Used Supabase MCP tool to verify actual table structure and discovered multiple mismatches:

### âŒ Issues Found
```typescript
// WRONG - What we thought existed:
{
    published_date: '...',              // âŒ Column doesn't exist
    reading_time_minutes: 5,            // âŒ Column name is wrong
    status: 'pending',                  // âŒ Column doesn't exist  
    metadata: {...},                    // âŒ Column doesn't exist
    content_type: '...'                 // âŒ Column doesn't exist
}
// Topics via junction table only      // âŒ Also direct ARRAY column

// WRONG - Timestamp handling:
published_at: ""                        // âŒ Empty string fails PostgreSQL validation
published_at: "2025-10-03 00:00:00 +0000 UTC"  // âŒ Invalid format
```

### âœ… Actual Schema (from Supabase)
```sql
CREATE TABLE content (
    id UUID PRIMARY KEY,
    url TEXT UNIQUE NOT NULL,
    title TEXT NOT NULL,
    description TEXT,
    domain TEXT NOT NULL,              -- âœ… EXISTS
    image_url TEXT,
    author TEXT,
    published_at TIMESTAMPTZ,          -- âœ… NOT published_date
    reading_time INTEGER,              -- âœ… NOT reading_time_minutes
    word_count INTEGER DEFAULT 0,
    content_text TEXT,
    topics TEXT[],                     -- âœ… ARRAY column (not just junction)
    quality_score NUMERIC,
    freshness_score NUMERIC,
    trending_score NUMERIC,
    base_score NUMERIC,
    popularity_score NUMERIC,
    is_active BOOLEAN DEFAULT true,
    ...
    -- NO status, metadata, or content_type columns
);
```

---

## âœ… Fixes Applied

### 1. Empty String Validation
```typescript
// Transform empty strings to undefined before validation
const emptyStringToUndefined = (val: any) => {
    if (typeof val === 'string' && val.trim() === '') return undefined;
    return val;
};

// All optional fields use preprocess
image_url: z.preprocess(emptyStringToUndefined, z.string().url().optional())
```

### 2. Timestamp Sanitization (New Fix)
```typescript
// Sanitize timestamps to ISO 8601 or null
const sanitizeTimestamp = (val: any): string | null => {
    if (!val || typeof val !== 'string') return null;
    
    const trimmed = val.trim();
    if (trimmed === '') return null;
    
    try {
        // Handle format: "2025-10-03 00:00:00 +0000 UTC"
        const cleaned = trimmed.replace(/ UTC$/, '');
        const date = new Date(cleaned);
        
        // Check if valid date
        if (isNaN(date.getTime())) return null;
        
        // Return ISO 8601 format
        return date.toISOString();
    } catch (error) {
        // Invalid date - return null instead of throwing
        return null;
    }
};

// Apply to published_date field
published_date: z.preprocess(sanitizeTimestamp, z.string().optional())
```

**What it fixes:**
- âœ… Empty strings â†’ `null` (not database error)
- âœ… `"2025-10-03 00:00:00 +0000 UTC"` â†’ `"2025-10-03T00:00:00.000Z"`
- âœ… Invalid formats â†’ `null` with warning logged
- âœ… Unparseable dates don't block entire row import

### 3. Correct Column Names
```typescript
// BEFORE (Wrong column names)
published_date: finalPublishedDate,     // âŒ
reading_time_minutes: readTime,         // âŒ
status: finalStatus,                    // âŒ
metadata: {...}                         // âŒ

// AFTER (Correct column names)
published_at: finalPublishedAt,         // âœ…
reading_time: readingTimeMinutes,       // âœ…
domain: domain,                         // âœ… (extracted from URL)
topics: finalTopics,                    // âœ… (ARRAY column)
// Removed: status, metadata, content_type
```

### 4. Non-Critical Optional Field Handling
```typescript
// Log warnings but don't fail import for bad optional values
const finalImageUrl = row.image_url || processedContent.image_url;
if (row.image_url && !finalImageUrl) {
    fastify.log.warn({ url, image_url: row.image_url }, 'Invalid image URL, skipping');
}

const finalPublishedAt = row.published_date || sanitizeTimestamp(processedContent.published_at);
if ((row.published_date || processedContent.published_at) && !finalPublishedAt) {
    fastify.log.warn({ url, timestamp: ... }, 'Invalid timestamp format, skipping');
}
```

**Benefits:**
- âœ… Invalid optional fields â†’ warning logged, field set to null
- âœ… Import continues successfully
- âœ… Users get feedback about data issues without blocking bulk upload

### 5. Topics Handling
```typescript
// Topics are stored BOTH ways:
// 1. Direct ARRAY column on content table
topics: finalTopics,  // ['tech', 'ai', 'ml']

// 2. Junction table for relational queries (optional, best-effort)
// Insert into content_topics with topic_id references
```

---

## ğŸ“Š Final Insert Structure

```typescript
await supabase
    .from('content')
    .insert({
        url,                              // âœ… Required
        title: finalTitle,                // âœ… Required
        description: finalDescription,    // âœ… Optional
        domain,                           // âœ… Required (from URL)
        topics: finalTopics,              // âœ… ARRAY of strings
        image_url: finalImageUrl,         // âœ… Optional (empty string â†’ NULL)
        author: finalAuthor,              // âœ… Optional
        published_at: finalPublishedAt,   // âœ… Timestamp
        word_count: wordCount || 0,       // âœ… Integer
        reading_time: readingMinutes || 0,// âœ… Integer
        content_text: scrapedText,        // âœ… Full content
        is_active: true                   // âœ… Boolean
    });
```

---

## ğŸ§ª Testing Checklist

Now ready to upload your CSV with:
- âœ… Empty optional fields (image_url, author, published_date, etc.)
- âœ… Domain values (extracted if not provided)
- âœ… Topics as comma-separated strings
- âœ… Reading time and word count
- âœ… Published dates in various formats (ISO 8601, UTC format, etc.)
- âœ… Invalid timestamps (will be logged and skipped, not fail import)
- âœ… All flexible column name variations

**Timestamp Format Examples:**
- âœ… `"2025-10-03T14:30:00Z"` â†’ Valid ISO 8601
- âœ… `"2025-10-03 00:00:00 +0000 UTC"` â†’ Sanitized to ISO 8601
- âœ… `""` â†’ Null (no error)
- âœ… `"invalid-date"` â†’ Null with warning logged

---

## ğŸ“ Key Learnings

1. **Always verify schema** - Use Supabase MCP tools to confirm actual structure
2. **Column names matter** - `reading_time` â‰  `reading_time_minutes`, `published_at` â‰  `published_date`
3. **Check for duplicates** - Some data (topics) stored in multiple places
4. **Handle nulls properly** - Empty strings must become undefined/null for validation
5. **Sanitize timestamps** - PostgreSQL requires valid ISO 8601 or null, not empty strings
6. **Make optional fields non-critical** - Invalid values shouldn't block entire import
7. **Don't assume migrations** - Features like `metadata` may not exist yet

---

## ğŸš€ Ready to Upload

Your `stumbleable_niche_20251004_023558_part1.csv` should now process successfully!

```powershell
# Start services
npm run dev

# Upload via admin dashboard
# http://localhost:3000/admin
```

Expected: All rows with proper URLs should insert successfully, with empty fields handled gracefully.
